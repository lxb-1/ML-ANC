# ML-ANC

## åŸºäºæœºå™¨å­¦ä¹ çš„æœ‰æºå™ªå£°æ§åˆ¶è®ºæ–‡å†™ä½œä»£ç 

æœ¬ç¨‹åºä¸»è¦ç ”ç©¶åŸºäºæœºå™¨å­¦ä¹ çš„æœ‰æºå™ªå£°æ§åˆ¶ç®—æ³•çš„è®¾è®¡ä¸æµ‹è¯•ï¼Œä¸»è¦ç ”ç©¶å†…å®¹å¦‚ä¸‹æ‰€ç¤ºï¼š

### ğŸŒ ç”¨åˆ°çš„çš„Githubä»£ç å¦‚ä¸‹æ‰€ç¤ºï¼š

#### ğŸ”Š éŸ³é¢‘å¤„ç†ç›¸å…³ä»“åº“ï¼š

- æˆ¿é—´éŸ³é¢‘ä¿¡å·å¤„ç†åŒ…ï¼š[LCAV/pyroomacoustics: Pyroomacoustics is a package for audio signal processing for indoor applications. It was developed as a fast prototyping platform for beamforming algorithms in indoor scenarios.](https://github.com/LCAV/pyroomacoustics) ğŸ“– [APIæ–‡æ¡£](https://pyroomacoustics.readthedocs.io/en/pypi-release/pyroomacoustics.datasets.html#)

- éŸ³é¢‘ç›®æ ‡è´¨é‡å’Œå¯è§£é‡Šæ€§æŒ‡æ ‡Pythonå®ç°ä»“åº“**pysepm**ï¼š[schmiph2/pysepm: Python implementation of performance metrics in Loizou's Speech Enhancement book](https://github.com/schmiph2/pysepm)

- **DeepFilterNetï¼š**[Rikorose/DeepFilterNet: Noise supression using deep filtering](https://github.com/Rikorose/DeepFilterNet)

- ç®€åŒ–çš„PythonéŸ³é¢‘ç‰¹å¾æå–åŒ…Spafeï¼š[SuperKogito/spafe: spafe: Simplified Python Audio Features Extraction](https://github.com/SuperKogito/spafe) ğŸ“– [APIæ–‡æ¡£](https://superkogito.github.io/spafe/v0.2.0/api_documentation.html)

- Play and Record Sound with Pythonï¼š[spatialaudio/python-sounddevice: Play and Record Sound with Python](https://github.com/spatialaudio/python-sounddevice) ğŸ“– [APIæ–‡æ¡£](https://python-sounddevice.readthedocs.io/en/0.4.5/index.html)

- [pyannote/pyannote-audio: Neural building blocks for speaker diarization: speech activity detection, speaker change detection, overlapped speech detection, speaker embedding](https://github.com/pyannote/pyannote-audio) [æ‰‹å†Œ](https://pyannote.github.io/pyannote-core/structure.html)

- Meta-AF: Meta-Learning for Adaptive Filters ([2022 arXiv](https://arxiv.org/pdf/2204.11942.pdf)) ï¼š[adobe-research/MetaAF: Control adaptive filters with neural networks.](https://github.com/adobe-research/MetaAF#demos)

- `LEAF`: A Learnable Audio Frontend : [google-research/leaf-audio: LEAF is a learnable alternative to audio features such as mel-filterbanks, that can be initialized as an approximation of mel-filterbanks, and then be trained for the task at hand, while using a very small number of parameters.](https://github.com/google-research/leaf-audio)

- [smitkiri/urban-sound-classification: Classification of audio signals using PyTorch](https://github.com/smitkiri/urban-sound-classification)
- 
- python_speech_featuresä»“åº“ï¼š[jameslyons/python_speech_features: This library provides common speech features for ASR including MFCCs and filterbank energies.](https://github.com/jameslyons/python_speech_features)
- [sambittarai/Audio-Signal-Processing-using-Deep-Learning: This repository includes an entire workflow for Audio Classification using Deep Learning.](https://github.com/sambittarai/Audio-Signal-Processing-using-Deep-Learning)

- âœ¨ WavEncoder:[shangeth/wavencoder: WavEncoder is a Python library for encoding audio signals, transforms for audio augmentation, and training audio classification models with PyTorch backend.](https://github.com/shangeth/wavencoder)ã€‚å®ƒè®¾è®¡äº†å¾ˆå¤šç‰¹æœ‰çš„å—å’Œå±‚ï¼Œå¯ä»¥å‚è€ƒæ–‡çŒ®ä¸­å…³äºWavEncoderçš„ç›¸å…³æ–‡çŒ®ã€‚

- âœ¨ éŸ³é¢‘ç½‘ç»œç½‘ç»œæ¶æ„SincNet:[mravanelli/SincNet: SincNet is a neural architecture for efficiently processing raw audio samples.](https://github.com/mravanelli/SincNet)

- **Speexdsp-python**ï¼š[xiongyihui/speexdsp-python: Speex Echo Canceller Python Library](https://github.com/xiongyihui/speexdsp-python)

- è¯­è¨€è¯†åˆ«åˆ°æ–‡æœ¬å®ç°ä»¥åŠåœ¨çº¿æ·±åº¦å­¦ä¹ å®ç°ä»“åº“ï¼ˆ36.4k starï¼‰ï¼š[CorentinJ/Real-Time-Voice-Cloning: Clone a voice in 5 seconds to generate arbitrary speech in real-time](https://github.com/CorentinJ/Real-Time-Voice-Cloning) ä½œè€…ç¡•å£«è®ºæ–‡é“¾æ¥ï¼š[Master thesis : Automatic Multispeaker Voice Cloning - s123578Jemine2019.pdf](https://matheo.uliege.be/bitstream/2268.2/6801/5/s123578Jemine2019.pdf)

- éŸ³ä¹éŸ³é¢‘pythonåˆ†æåŒ…ï¼š[librosa/librosa: Python library for audio and music analysis](https://github.com/librosa/librosa)

- PyTorch-Kaldiè¯­éŸ³è¯†åˆ«å·¥å…·åŒ…ï¼š[mravanelli/pytorch-kaldi: pytorch-kaldi is a project for developing state-of-the-art DNN/RNN hybrid speech recognition systems. The DNN part is managed by pytorch, while feature extraction, label computation, and decoding are performed with the kaldi toolkit.](https://github.com/mravanelli/pytorch-kaldi)

- ï¼ˆFaceBookï¼‰å‰æ²¿åºåˆ—å»ºæ¨¡å·¥å…·åŒ…ï¼ˆFairseqï¼‰ï¼š[facebookresearch/fairseq: Facebook AI Research Sequence-to-Sequence Toolkit written in Python.](https://github.com/facebookresearch/fairseq)

- Speechbrainï¼š[speechbrain/speechbrain: A PyTorch-based Speech Toolkit](https://github.com/speechbrain/speechbrain)

#### ğŸ¦„ å¤šç›®æ ‡ä¼˜åŒ–ä»“åº“

- ğŸï¸ å¤šç›®æ ‡ä¼˜åŒ–ç›¸å…³çš„è§†é¢‘ï¼š
  - âœ¨ [å¤šç›®æ ‡ä¼˜åŒ–_å“”å“©å“”å“©_bilibili](https://www.bilibili.com/video/BV17S4y1M7oU/?spm_id_from=333.337.search-card.all.click&vd_source=5a45e7b7d8a4889aab6645f3fbfd5fee)

- âœ¨ **pymoo:** Multi-objective Optimization in Python : [anyoptimization/pymoo: NSGA2, NSGA3, R-NSGA3, MOEAD, Genetic Algorithms (GA), Differential Evolution (DE), CMAES, PSO](https://github.com/anyoptimization/pymoo)
  - ğŸ  [pymoo å®˜ç½‘åŠæ‰‹å†Œ](https://www.pymoo.org/)
  - ğŸ“– [è®ºæ–‡ï¼šPymmo: Multi-Objective Optimization in Python](https://ieeexplore.ieee.org/document/9078759)

- âœ¨ Geatpy 2 ï¼š The Genetic and Evolutionary Algorithm Toolbox for Python with high performance : [geatpy-dev/geatpy: Evolutionary algorithm toolbox and framework with high performance for Python](https://github.com/geatpy-dev/geatpy)
  - ğŸ  [Geatpy](http://geatpy.com/)

- âœ¨ DEAP, a novel evolutionary cimputation frmework for rapid prototyping and testing of ideas : [DEAP/deap: Distributed Evolutionary Algorithms in Python](https://github.com/DEAP/deap)
  - ğŸ  [DEAP documentation â€” DEAP 1.3.3 documentation](https://deap.readthedocs.io/en/master/)

- âœ¨ å¤šç›®æ ‡å¯å‘å¼ç®—æ³• Github ä»“åº“ï¼š[YuLi2022/MOEA-CODE-PYTHON: pythonå®ç°å¤šç›®æ ‡å¯å‘å¼ç®—æ³•](https://github.com/YuLi2022/MOEA-CODE-PYTHON)
  - ğŸ“– 1ã€MODAï¼šå¤šç›®æ ‡æŸ¥åˆ†è¿›åŒ–ç®—æ³•ï¼š[å¤šç›®æ ‡å·®åˆ†è¿›åŒ–åœ¨çƒ­è¿è½§è´Ÿè·åˆ†é…ä¸­çš„åº”ç”¨ - ä¸­å›½çŸ¥ç½‘](https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFD2010&filename=KZLY201007012&v=eACTLuuWgXCuSeHoCPfbYi6ACKx9earJFmPbFIEKL1eHZHWXctiVGXjkP5L0FVQO)
  - ğŸŒ 2ã€NSGA2 ï¼š[(56æ¡æ¶ˆæ¯) å¤šç›®æ ‡ä¼˜åŒ–ç®—æ³•ï¼ˆä¸€ï¼‰NSGA-â…¡ï¼ˆNSGA2ï¼‰_æ™“é£wangchaoçš„åšå®¢-CSDNåšå®¢_å¤šç›®æ ‡ä¼˜åŒ–ç®—æ³•](https://blog.csdn.net/qq_40434430/article/details/82876572)
  - ğŸ“– 3ã€MOPSO ï¼šå¤šç›®æ ‡ç²’å­ç¾¤ç®—æ³•ï¼š[MOPSOç®—æ³•åŠå…¶åœ¨æ°´åº“ä¼˜åŒ–è°ƒåº¦ä¸­çš„åº”ç”¨ - ä¸­å›½çŸ¥ç½‘](https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFD2007&filename=JSJC200718086&v=dGa1CTuXauWtahkDR3gOl6bdGGX8ycO6eRIycbCzkXYy2t91HEzutO66IGH%25mmd2BGf08)

- âœ¨ SPEA2 Github ä»“åº“ (Strength Pareto Evolutionary Algorithm v2) : [Jagoslav/SPEA2: Strength Pareto Evolutionary Algorithm v2 implementation in python](https://github.com/Jagoslav/SPEA2)

- å¯»æ‰¾ä¸€ä¸ªå¤§é‡ç‚¹é›†çš„ `pareto front` çš„å¿«é€Ÿå®ç°æ–¹æ³•ä»“åº“ ï¼š[KoenGoe/FastPareto: Fast implementations for finding pareto front in set of points](https://github.com/KoenGoe/FastPareto)

- Pareto-hypernetworks : [AvivNavon/pareto-hypernetworks: Official implementation of Learning The Pareto Front With HyperNetworks [ICLR 2021]](https://github.com/AvivNavon/pareto-hypernetworks)

- [jMetal/jMetalPy: A framework for single/multi-objective optimization with metaheuristics](https://github.com/jMetal/jMetalPy#installation) ğŸ“š [jMetal/jMetaalPYå¸®åŠ©æ–‡æ¡£](https://jmetal.github.io/jMetalPy/tutorials/observer.html)

#### ğŸ›ï¸ å¹¶è¡Œè®¡ç®—ç›¸å…³ä»“åº“ï¼š
- Dask : A flexible parallel computing library for analytics : [dask/dask: Parallel computing with task scheduling](https://github.com/dask/dask)
  - ğŸ“š [Dask æ–‡æ¡£](https://docs.dask.org/en/latest/install.html)
  - ğŸ  [Dask å®˜ç½‘](https://www.dask.org/)

#### ğŸ“Š åŸºäºPytorchçš„éŸ³é¢‘ç›¸å…³æŸå¤±å‡½æ•°åˆè®¡ä»“åº“ï¼š[csteinmetz1/auraloss: Collection of audio-focused loss functions in PyTorch](https://github.com/csteinmetz1/auraloss)

ç›¸å…³è®ºæ–‡é“¾æ¥å¦‚ä¸‹è¡¨æ‰€ç¤ºï¼š

<table>
    <tr>
        <th>Loss function</th>
        <th>Interface</th>
        <th>Reference</th>
    </tr>
    <tr>
        <td colspan="3" align="center"><b>Time domain</b></td>
    </tr>
    <tr>
        <td>Error-to-signal ratio (ESR)</td>
        <td><code>auraloss.time.ESRLoss()</code></td>
        <td><a href=https://arxiv.org/abs/1911.08922>Wright & VÃ¤limÃ¤ki, 2019</a></td>
    </tr>
    <tr>
        <td>DC error (DC)</td>
        <td><code>auraloss.time.DCLoss()</code></td>
        <td><a href=https://arxiv.org/abs/1911.08922>Wright & VÃ¤limÃ¤ki, 2019</a></td>
    </tr>
    <tr>
        <td>Log hyperbolic cosine (Log-cosh)</td>
        <td><code>auraloss.time.LogCoshLoss()</code></td>
        <td><a href=https://openreview.net/forum?id=rkglvsC9Ym>Chen et al., 2019</a></td>
    </tr>
    <tr>
        <td>Signal-to-noise ratio (SNR)</td>
        <td><code>auraloss.time.SNRLoss()</code></td>
        <td></td>
    </tr>
    <tr>
        <td>Scale-invariant signal-to-distortion <br>  ratio (SI-SDR)</td>
        <td><code>auraloss.time.SISDRLoss()</code></td>
        <td><a href=https://arxiv.org/abs/1811.02508>Le Roux et al., 2018</a></td>
    </tr>
    <tr>
        <td>Scale-dependent signal-to-distortion <br>  ratio (SD-SDR)</td>
        <td><code>auraloss.time.SDSDRLoss()</code></td>
        <td><a href=https://arxiv.org/abs/1811.02508>Le Roux et al., 2018</a></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><b>Frequency domain</b></td>
    </tr>
    <tr>
        <td>Aggregate STFT</td>
        <td><code>auraloss.freq.STFTLoss()</code></td>
        <td><a href=https://arxiv.org/abs/1808.06719>Arik et al., 2018</a></td>
    </tr>
    <tr>
        <td>Aggregate Mel-scaled STFT</td>
        <td><code>auraloss.freq.MelSTFTLoss(sample_rate)</code></td>
        <td></td>
    </tr>
    <tr>
        <td>Multi-resolution STFT</td>
        <td><code>auraloss.freq.MultiResolutionSTFTLoss()</code></td>
        <td><a href=https://arxiv.org/abs/1910.11480>Yamamoto et al., 2019*</a></td>
    </tr>
    <tr>
        <td>Random-resolution STFT</td>
        <td><code>auraloss.freq.RandomResolutionSTFTLoss()</code></td>
        <td><a href=https://www.christiansteinmetz.com/s/DMRN15__auraloss__Audio_focused_loss_functions_in_PyTorch.pdf>Steinmetz & Reiss, 2020</a></td>
    </tr>
    <tr>
        <td>Sum and difference STFT loss</td>
        <td><code>auraloss.freq.SumAndDifferenceSTFTLoss()</code></td>
        <td><a href=https://arxiv.org/abs/2010.10291>Steinmetz et al., 2020</a></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><b>Perceptual transforms</b></td>
    </tr>
    <tr>
        <td>Sum and difference signal transform</td>
        <td><code>auraloss.perceptual.SumAndDifference()</code></td>
        <td><a href=#></a></td>
    </tr>
    <tr>
        <td>FIR pre-emphasis filters</td>
        <td><code>auraloss.perceptual.FIRFilter()</code></td>
        <td><a href=https://arxiv.org/abs/1911.08922>Wright & VÃ¤limÃ¤ki, 2019</a></td>
    </tr>
</table>

\* [Wang et al., 2019](https://arxiv.org/abs/1904.12088) also propose a multi-resolution spectral loss (that [Engel et al., 2020](https://arxiv.org/abs/2001.04643) follow), 
but they do not include both the log magnitude (L1 distance) and spectral convergence terms, introduced in [Arik et al., 2018](https://arxiv.org/abs/1808.0671), and then extended for the multi-resolution case in [Yamamoto et al., 2019](https://arxiv.org/abs/1910.11480).


#### æ§åˆ¶ç³»ç»Ÿä»“åº“

- åŸºäº Python çš„æ§åˆ¶ç³»ç»Ÿï¼š[python-control/python-control: The Python Control Systems Library is a Python module that implements basic operations for analysis and design of feedback control systems.](https://github.com/python-control/python-control) ğŸ“– [APIæ–‡æ¡£](https://python-control.readthedocs.io/en/latest/intro.html)

#### ğŸŒ€ åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªé€‚åº”æ»¤æ³¢ç›¸å…³ä»“åº“ï¼š
- Meta-AF: åŸºäºMeta-Learningçš„è‡ªé€‚åº”æ»¤æ³¢ä»“åº“ï¼š[adobe-research/MetaAF: Control adaptive filters with neural networks.](https://github.com/adobe-research/MetaAF)
- Auto-DSPï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„å£°å­¦å›å£°æ¶ˆé™¤å™¨ä¼˜åŒ–ä»“åº“ï¼š[jmcasebeer/autodsp: Train custom adaptive filter optimizers without hand tuning or extra labels.](https://github.com/jmcasebeer/autodsp)


### ğŸ“š å¸®åŠ©æ–‡æ¡£ï¼š
- pyroomacousticsæˆ¿é—´éŸ³é¢‘å¤„ç†åŒ…å¸®åŠ©æ‰‹å†Œé“¾æ¥ï¼š[Contributing â€” Pyroomacoustics 0.6.0 documentation](https://pyroomacoustics.readthedocs.io/en/pypi-release/contributing.html)

- python_speech_featuresåŒ…å¸®åŠ©æ–‡æ¡£é“¾æ¥ï¼š[Welcome to python_speech_featuresâ€™s documentation! â€” python_speech_features 0.1.0 documentation](https://python-speech-features.readthedocs.io/en/latest/)

- éŸ³ä¹éŸ³é¢‘pythonåˆ†æåŒ…æ¡ˆä¾‹é“¾æ¥ï¼š[Advanced examples â€” librosa 0.9.2 documentation](https://librosa.org/doc/latest/advanced.html)
- éŸ³ä¹éŸ³é¢‘pythonåˆ†æåŒ…å¸®åŠ©æ–‡æ¡£é“¾æ¥ï¼š[librosa â€” librosa 0.9.2 documentation](https://librosa.org/doc/latest/index.html)

- ï¼ˆFaceBookï¼‰å‰æ²¿åºåˆ—å»ºæ¨¡å·¥å…·åŒ…ï¼ˆFairseqï¼‰å¸®åŠ©æ–‡æ¡£é“¾æ¥ï¼š[fairseq documentation â€” fairseq 0.12.2 documentation](https://fairseq.readthedocs.io/en/latest/index.html)


### ğŸ“° ç›¸å…³è®ºæ–‡é“¾æ¥
- [Sparse R-CNN: End-to-End Object Detection with Learnable Proposals](https://arxiv.org/pdf/2011.12450.pdf)
- SincNetï¼š[[1808.00158] Speaker Recognition from Raw Waveform with SincNet](https://arxiv.org/abs/1808.00158)

#### WavEncoderä»“åº“ç›¸å…³çš„æ–‡çŒ®ï¼š
- `SoftAttention`ç±»çš„å®ç°è®ºæ–‡ï¼š[Attention-based End-to-End Models for Small-Footprint Keyword Spotting](https://arxiv.org/pdf/1803.10916.pdf)ã€‚Githubä»“åº“ï¼š[isadrtdinov/kws-attention: Attention-based model for keywords spotting](https://github.com/isadrtdinov/kws-attention)

#### åŸºäºæ·±åº¦å­¦ä¹ çš„è‡ªé€‚åº”æ»¤æ³¢ç›¸å…³æ–‡çŒ®ï¼š
- Meta-AF: åŸºäºMeta-Learningçš„è‡ªé€‚åº”æ»¤æ³¢æ–‡çŒ®ï¼š[[2204.11942] Meta-AF: Meta-Learning for Adaptive Filters](https://arxiv.org/abs/2204.11942)
- Auto-DSPï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„å£°å­¦å›å£°æ¶ˆé™¤å™¨ä¼˜åŒ–æ–‡çŒ®ï¼š[[2110.04284] Auto-DSP: Learning to Optimize Acoustic Echo Cancellers](https://arxiv.org/abs/2110.04284)

ğŸ’¿ **éŸ³é¢‘æ•°æ®é›†**ï¼š

- TIMITéŸ³é¢‘æ•°æ®é›†ï¼š[TIMIT Corpus â€” Pyroomacoustics 0.6.0 documentation](https://pyroomacoustics.readthedocs.io/en/pypi-release/pyroomacoustics.datasets.timit.html#the-timit-dataset)

- å›éŸ³æ¶ˆé™¤ç ”ç©¶æ•°æ®é›†ï¼ˆAEC-Challengeï¼‰ï¼š[microsoft/AEC-Challenge: AEC Challenge](https://github.com/microsoft/AEC-Challenge) [ç›¸å…³è®ºæ–‡ï¼šICASSP 2021 Acoustic Echo Cancellation Challenge: Datasets, Testing Framework, and Results](https://arxiv.org/pdf/2009.04972.pdf)